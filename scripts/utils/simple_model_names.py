from typing import Mapping

MODEL_SIMPLE_NAMES: Mapping[str, str] = {
    "gpt-4": "gpt-4",
    "gpt-3.5-turbo": "gpt-3.5-turbo",
    "claude-2": "claude-2",
    "claude-instant-1": "claude-instant-1",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7ryTmccr": "Finetuned 6000 COTs with unbiased questions",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7semB2r8": "Finetuned 6000 COTs with 3 different types of biased questions,<br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7uWGH06b": "Finetuned 6000 COTs with 5 different types of biased questions,<br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7uXhCnI7": "Finetuned 6000 COTs with 5 different types of biased questions,<br> leaving out bias of Wrong Fewshot, make sure these actually biased the model",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7t5OEDT9": "Finetuned 18000 COTs with biased questions,<br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7vVCogry": "Finetuned 72000 COTs with 5 different types of biased questions,<br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7tmQDS49": "Finetuned 72000 COTS with biased questions",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7t8IvMic": "Finetuned 18000 COTs with unbiased questions",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7rg7aRbV": "Finetuned 6000 COTs with biased questions,<br> including ALL biases",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7skb05DZ": "Finetuned 6000 COTs with biased questions,<br> leaving out bias of I think the answer is (X)",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7smTRQCv": "Finetuned 6000 COTs with biased questions,<br> leaving out bias of Stanford Professor opinion",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7soRFrpt": "Finetuned 6000 COTs with biased questions,<br> leaving out bias of More Reward for (X)",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7wWkPEKY": "Finetuned 72000 COTs",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::80R5ewb3": "Finetuned 95%  COTs, biased questions,<br> 5%  non cots, unbiased questions <br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::80nD19wy": "Finetuned 64800 non COTs, biased questions,<br> 7200 cots, unbiased questions <br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::813SHRdF": "Finetuned 98% (70560) non COTs, biased questions,<br> 2% (1440) cots, unbiased questions <br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::81I9aGR0": "All unbiased 98% COT, 2% non COT",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::81Eu4Gp5": "Finetuned 98% (70560) COTs, biased questions,<br> 7200 2% (1440) non cots, unbiased questions <br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::81c693MV": "50% biased COT, 50% biased non COT",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::82lIvjbP": "50% unbiased COT, 50% unbiased non COT",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::83O1S0zn": "50% biased COT, 50% biased non COT, dumb brained",
    "davinci:ft-academicsnyuperez-2023-09-20-00-03-37": "davinci-ft-1k-qm_a",
    "davinci:ft-academicsnyuperez-2023-09-27-01-56-27": "davinci-ft-10k-50-50",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez:df1-df2-qmist-ans:80fDVj77": "gpt-3.5-ft-1k-qm_a",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez:df1-df2-q-ans:80erGhif": "gpt-3.5-ft-1k-q_a",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7yyd6GaT": "gpt-3.5-ft-72k",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez:qma0-100:836qD9hb": "gpt-3.5-ft-10k-0-100",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez:qma50-50:835v7CGz": "gpt-3.5-ft-10k-50-50",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez:qma75-25:836CTiOE": "gpt-3.5-ft-10k-75-25",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez:qma100-0:83736Y7N": "gpt-3.5-ft-10k-100-0",
}
