from typing import Mapping

MODEL_SIMPLE_NAMES: Mapping[str, str] = {
    "gpt-4": "gpt-4",
    "gpt-3.5-turbo": "gpt-3.5-turbo",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7ryTmccr": "Finetuned 6000 COTs with unbiased questions",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7semB2r8": "Finetuned 6000 COTs with 3 different types of biased questions,<br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7uWGH06b": "Finetuned 6000 COTs with 5 different types of biased questions,<br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7uXhCnI7": "Finetuned 6000 COTs with 5 different types of biased questions,<br> leaving out bias of Wrong Fewshot, make sure these actually biased the model",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7t5OEDT9": "Finetuned 18000 COTs with biased questions,<br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7vVCogry": "Finetuned 72000 COTs with 5 different types of biased questions,<br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7tmQDS49": "Finetuned 72000 COTS with biased questions",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7t8IvMic": "Finetuned 18000 COTs with unbiased questions",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7rg7aRbV": "Finetuned 6000 COTs with biased questions,<br> including ALL biases",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7skb05DZ": "Finetuned 6000 COTs with biased questions,<br> leaving out bias of I think the answer is (X)",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7smTRQCv": "Finetuned 6000 COTs with biased questions,<br> leaving out bias of Stanford Professor opinion",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7soRFrpt": "Finetuned 6000 COTs with biased questions,<br> leaving out bias of More Reward for (X)",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::7wWkPEKY": "Finetuned 72000 COTs",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::80R5ewb3": "Finetuned 95%  COTs, biased questions,<br> 5%  non cots, unbiased questions <br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::80nD19wy": "Finetuned 64800 non COTs, biased questions,<br> 7200 cots, unbiased questions <br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::813SHRdF": "Finetuned 98% (70560) non COTs, biased questions,<br> 2% (1440) cots, unbiased questions <br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::81I9aGR0": "All unbiased 98% COT, 2% non COT",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::81Eu4Gp5": "Finetuned 98% (70560) COTs, biased questions,<br> 7200 2% (1440) non cots, unbiased questions <br> leaving out bias of Wrong Fewshot",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::81c693MV": "50% biased COT, 50% biased non COT (72k)",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::83O1S0zn": "50% biased COT, 50% biased non COT, dumb brained",
    "ft:gpt-3.5-turbo-0613:far-ai::88CAIEy4": "Finetuned on modally correct outputs, logiqa & mmlu (2390)",
    "ft:gpt-3.5-turbo-0613:far-ai::88FWLOk7": "Finetuned on modally correct outputs, COT_TRAINING_TASKS (2650)",
    "ft:gpt-3.5-turbo-0613:far-ai::88dVFSpt": "Consistent prompt sensitivity, COT_TRAINING_TASKS (2000)",
    "ft:gpt-3.5-turbo-0613:far-ai::89d1Jn8z": "Prompt Sen Consistency 100",
    "ft:gpt-3.5-turbo-0613:far-ai::89dSzlfs": "Prompt Sen Consistency 1000",
    "ft:gpt-3.5-turbo-0613:far-ai::89dxzRjA": "Prompt Sen Consistency 10000",
    "ft:gpt-3.5-turbo-0613:far-ai::89figOP6": "Prompt Sen Consistency 50000",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::88h1pB4E": "50% unbiased COT, 50% unbiased non COT (72k)",
    "ft:gpt-3.5-turbo-0613:far-ai::8AhgtHQw": "Prompt Sen 2 10k, include all formatters",
    "ft:gpt-3.5-turbo-0613:far-ai::8Ahe3cBv": "Prompt Sen 2 10k, don't include all formatters",
    "ft:gpt-3.5-turbo-0613:far-ai::8AjeHchR": "Promp Sen 2 50k don't include all formatters",
    "ft:gpt-3.5-turbo-0613:far-ai::8Aic3f0n": "Promp Sen 2 50k include all formatters",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::89nGUACf": "10k 50% CoT / 50% Non Cot, Few Shot Biases, 10% Instruction",
    "ft:gpt-3.5-turbo-0613:academicsnyuperez::8B24hv5w": "10k, 100% CoT, Few Shot Biases, 0% Instruction",
    "ft:gpt-3.5-turbo-0613:far-ai::8BRpCYNt": "# 110, 50/50 train on zero shot",
    "ft:gpt-3.5-turbo-0613:far-ai::8BSJekFR": "# 1100, 50/50 train on zero shot",
    "ft:gpt-3.5-turbo-0613:far-ai::8BSeBItZ": "# 11000, 50/50 train on zero shot",
    "ft:gpt-3.5-turbo-0613:far-ai::8BSkM7rh": "# 22000, 50/50 train on zero shot",
    "ft:gpt-3.5-turbo-0613:far-ai::8Bk36Zdf": "# 110, 50/50 train on prompt variants",
    "ft:gpt-3.5-turbo-0613:far-ai::8Bmh8wJf": "# 1100, 50/50 train on prompt variants",
    "ft:gpt-3.5-turbo-0613:far-ai::8Bn9DgF7": "# 11000, 50/50 train on prompt variants",
    "ft:gpt-3.5-turbo-0613:far-ai::8Boiwe8c": "# 22000, 50/50 train on prompt variants",
    "ft:gpt-3.5-turbo-0613:far-ai::8GQiNe1D": "1k all correct (control)",
    "ft:gpt-3.5-turbo-0613:far-ai::8G1NdOHF": "1k super dataset all correct (ours)",
}
